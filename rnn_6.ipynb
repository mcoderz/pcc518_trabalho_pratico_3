{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topico</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coconut-oil</td>\n",
       "      <td>us scientists say tropical oils health risk au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coconut-oil</td>\n",
       "      <td>vegetable oils may tighten despite seed surplu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coconut-oil</td>\n",
       "      <td>corrected philippines criticises ec for oil le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coconut-oil</td>\n",
       "      <td>coconut oil contract to change dutch traders r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alum</td>\n",
       "      <td>feb daily ave unwrought aluminium output tonne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        topico                                              texto\n",
       "0  coconut-oil  us scientists say tropical oils health risk au...\n",
       "1  coconut-oil  vegetable oils may tighten despite seed surplu...\n",
       "2  coconut-oil  corrected philippines criticises ec for oil le...\n",
       "3  coconut-oil  coconut oil contract to change dutch traders r...\n",
       "4         alum  feb daily ave unwrought aluminium output tonne..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_training.csv\", sep=',',usecols=[\"topico\", \"texto\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['coconut-oil', 'alum', 'rye', 'money-fx', 'copper', 'potato',\n",
       "       'rubber', 'dlr', 'iron-steel', 'soy-meal', 'sunseed', 'rapeseed',\n",
       "       'retail', 'silver', 'copra-cake', 'interest', 'platinum',\n",
       "       'palmkernel', 'nkr', 'nzdlr', 'oat', 'acq', 'palladium', 'unknown',\n",
       "       'groundnut', 'livestock', 'groundnut-oil', 'oilseed', 'dfl',\n",
       "       'wheat', 'rice', 'cotton', 'ship', 'gnp', 'lin-oil',\n",
       "       'money-supply', 'sun-meal', 'l-cattle', 'rape-oil', 'earn',\n",
       "       'nat-gas', 'hog', 'castor-oil', 'income', 'gas', 'sugar',\n",
       "       'veg-oil', 'sorghum', 'lei', 'fuel', 'sun-oil', 'soy-oil', 'tea',\n",
       "       'propane', 'soybean', 'grain', 'naphtha', 'lead', 'wpi', 'crude',\n",
       "       'lumber', 'strategic-metal', 'coffee', 'rand', 'ipi', 'heat',\n",
       "       'bop', 'barley', 'cpu', 'jet', 'palm-oil', 'dmk', 'pet-chem',\n",
       "       'jobs', 'tin', 'zinc', 'orange', 'corn', 'cotton-oil', 'nickel',\n",
       "       'reserves', 'cpi', 'coconut', 'housing', 'trade', 'carcass',\n",
       "       'cocoa', 'instal-debt', 'yen', 'meal-feed', 'gold'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topico.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df.topico.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = df['topico'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    df['texto'], df['topico'],\n",
    "    test_size=0.33,\n",
    "    random_state=53) # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 64\n",
    "VOCABULARY_SIZE = None # None mantem todas as palavras\n",
    "OOV_TOK = '<OOV>'\n",
    "TRUNCATE_TYPE = 'post'\n",
    "PADDING_TYPE = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a mediana do tamanho dos textos no conjunto e torna esse valor o tamanho m√°ximo dos textos.\n",
    "text_len = []\n",
    "for i in list(x_train) + list(x_val):\n",
    "    text_len.append(len(i))\n",
    "\n",
    "MAX_LENGTH = np.median(text_len)\n",
    "MAX_LENGTH = max_length.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE, oov_token=OOV_TOK)\n",
    "tokenizer.fit_on_texts(list(x_train) + list(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_val_sequences = tokenizer.texts_to_sequences(x_val)\n",
    "word_index = tokenizer.word_index\n",
    "print('Vocabulary size:', len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = pad_sequences(x_train_sequences, maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATE_TYPE)\n",
    "x_val_pad = pad_sequences(x_val_sequences, maxlen=MAX_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATE_TYPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer = Tokenizer(filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "label_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "training_label_seq = np.array(label_tokenizer.texts_to_sequences(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer = Tokenizer(filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "label_tokenizer.fit_on_texts(list(y_val))\n",
    "\n",
    "val_label_seq = np.array(label_tokenizer.texts_to_sequences(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index) + 1, EMBEDDING_DIMENSION),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(EMBEDDING_DIMENSION)),\n",
    "    tf.keras.layers.Dense(EMBEDDING_DIMENSION, activation='relu'),\n",
    "    tf.keras.layers.Dense(92, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy']) \n",
    "# https://keras.io/api/models/model_training_apis/ ; https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "history = model.fit(x_train_pad, training_label_seq, epochs=num_epochs, validation_data=(x_val_pad, val_label_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efde34d10431e78146c56074b710b4f7e5e083279935c85f31bd0be7c32811bf"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('outro_um': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
