{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/abner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/abner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list (file_name):\n",
    "    \"\"\"\n",
    "    Converte o CSV em duas lista distintas:\n",
    "    articles e labels\n",
    "    \"\"\"\n",
    "    articles = []\n",
    "    labels = []\n",
    "\n",
    "    with open(file_name, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            labels.append(row[1])\n",
    "            article = (row[3])\n",
    "            for word in STOPWORDS:\n",
    "                token = ' ' + word + ' '\n",
    "                article = article.replace(token, ' ')\n",
    "                article = article.replace(' ', ' ')\n",
    "            articles.append(article)\n",
    "    \n",
    "    return labels, articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11413\n",
      "11413\n"
     ]
    }
   ],
   "source": [
    "labels = csv_to_list('data_training.csv')[0]\n",
    "category = csv_to_list('data_training.csv')[1]\n",
    "\n",
    "print(len(category))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a mediana do tamanho dos textos no conjunto e torna esse valor o tamanho m√°ximo dos textos.\n",
    "text_len = []\n",
    "for i in category:\n",
    "    text_len.append(len(i))\n",
    "\n",
    "max_length = np.median(text_len)\n",
    "max_length = max_length.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11413, 428)\n",
      "31734\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(category)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size=len(word_index)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(category)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(padded.shape)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(category) * training_portion)\n",
    "\n",
    "training_sequences = padded[0:train_size]\n",
    "training_labels = labels[0:train_size]\n",
    "\n",
    "validation_sequences = padded[train_size:]\n",
    "validation_labels = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer = Tokenizer(filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "label_tokenizer.fit_on_texts(labels)\n",
    "\n",
    "training_label_seq = np.array(label_tokenizer.texts_to_sequences(training_labels))\n",
    "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))\n",
    "\n",
    "training_label_seq = tf.keras.utils.to_categorical(training_label_seq)\n",
    "validation_label_seq = tf.keras.utils.to_categorical(validation_label_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9130, 428)\n",
      "(9130, 91)\n",
      "(2283, 428)\n",
      "(2283, 92)\n"
     ]
    }
   ],
   "source": [
    "print(training_sequences.shape)\n",
    "print(training_label_seq.shape)\n",
    "print(validation_sequences.shape)\n",
    "print(validation_label_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4024\n",
      "4024\n"
     ]
    }
   ],
   "source": [
    "test_labels = csv_to_list('data_test.csv')[0]\n",
    "test_category = csv_to_list('data_test.csv')[1]\n",
    "\n",
    "print(len(test_category))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4024, 428)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(test_category)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_category)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4024, 1)\n"
     ]
    }
   ],
   "source": [
    "label_tokenizer = Tokenizer(filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "label_tokenizer.fit_on_texts(test_labels)\n",
    "\n",
    "test_label_seq = np.array(label_tokenizer.texts_to_sequences(test_labels))\n",
    "\n",
    "print(test_label_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66],\n",
       "       [66],\n",
       "       [66],\n",
       "       ...,\n",
       "       [21],\n",
       "       [21],\n",
       "       [21]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 428, 100)          3179800   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 92)                9292      \n",
      "=================================================================\n",
      "Total params: 3,369,992\n",
      "Trainable params: 3,369,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(training_vocab_size+1, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(92, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy']) # https://keras.io/api/models/model_training_apis/ ; https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9130 samples, validate on 2283 samples\n",
      "9130/9130 - 556s - loss: 1.7731 - accuracy: 0.5039 - val_loss: 8.6979 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "history = model.fit(training_sequences, training_label_seq, epochs=num_epochs, validation_data=(validation_sequences, validation_label_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.plot(history.history['accuracy'], label='train loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(test_padded, test_label_seq, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_padded)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(test_label_seq, y_pred_bool)) #https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print f1, precision, and recall scores\n",
    "print(precision_score(test_label_seq, y_pred_bool , average=\"macro\"))\n",
    "print(recall_score(test_label_seq, y_pred_bool , average=\"macro\"))\n",
    "print(f1_score(test_label_seq, y_pred_bool , average=\"macro\"))\n",
    "print(accuracy_score(test_label_seq, y_pred_bool ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efde34d10431e78146c56074b710b4f7e5e083279935c85f31bd0be7c32811bf"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('outro_um': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
